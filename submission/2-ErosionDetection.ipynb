{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt \n",
    "# from matplotlib import figure, colors\n",
    "# from matplotlib.patches import Rectangle\n",
    "# from data import visualize, visualize_multiple\n",
    "# import PIL.ExifTags\n",
    "# from PIL import ImageOps\n",
    "# import xmltodict\n",
    "# from torchvision.transforms import functional as F\n",
    "# from engine import train_one_epoch\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from data import ID_TO_NAME_MAP_EROSION as ID_TO_NAME_MAP, NAME_TO_ID_MAP_EROSION as NAME_TO_ID_MAP, RADataSet\n",
    "from model import fasterrcnn_resnet50_fpn\n",
    "import utils.transforms, utils.datasets, utils.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = '/output'\n",
    "#handle = './output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('0')\n",
    "hdlr = logging.FileHandler(handle + '/logs/2-erosiondetection.log')\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s]   %(message)s')\n",
    "hdlr.setFormatter(formatter)\n",
    "logger.addHandler(hdlr) \n",
    "logger.setLevel(logging.INFO)\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setFormatter(formatter)\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-14 01:57:05,763][INFO]   INPUT:./output/test, OUTPUT:./output/test/erosion_all, PRETRAIN_MODEL:./pretrained_models/saved_model_30_epochs_erosion_from_synthetic_to_full.txt\n"
     ]
    }
   ],
   "source": [
    "INPUT = handle + '/test'\n",
    "JOINTOUTPUT = handle + '/test/erosion_all'\n",
    "PRETRAIN_MODEL = './pretrained_models/saved_model_30_epochs_erosion_from_synthetic_to_full.txt'\n",
    "logger.info (f'INPUT:{INPUT}, OUTPUT:{JOINTOUTPUT}, PRETRAIN_MODEL:{PRETRAIN_MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set score = Erosion\n"
     ]
    }
   ],
   "source": [
    "dataset = RADataSet(INPUT,transforms=utils.transforms.get_transform(train=True), score='Erosion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-14 01:57:08,970][INFO]   Size of dataset: 4\n",
      "[2020-05-14 01:57:08,971][INFO]   Number of joints: 45\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(ID_TO_NAME_MAP)\n",
    "logger.info(f'Size of dataset: {len(dataset)}')\n",
    "logger.info(f'Number of joints: {num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-14 01:57:26,152][INFO]   Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = 'cpu'\n",
    "model = fasterrcnn_resnet50_fpn(num_classes=num_classes, saved_model = PRETRAIN_MODEL)\n",
    "model.to(device);\n",
    "logger.info(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(PRETRAIN_MODEL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_prediction(prediction, threshold = 0.2, filter_labels = None):\n",
    "    if filter_labels is None:\n",
    "        filter_labels = np.array(prediction['labels'].cpu())\n",
    "    labels = np.array(prediction['labels'].cpu())\n",
    "    scores = np.array(prediction['scores'].cpu())\n",
    "    boxes = np.array(prediction['boxes'].cpu())\n",
    "    filtered_prediction = {'labels':[], 'scores':[], 'boxes':[]}\n",
    "    for label in set(filter_labels):\n",
    "        loc = np.where(labels == label)[0]\n",
    "        if len(loc) > 0: \n",
    "            label_scores = scores[loc]\n",
    "            if max(label_scores) > threshold:\n",
    "                box = boxes[loc[np.where(label_scores == max(label_scores))]]\n",
    "                filtered_prediction['labels'].append(label)\n",
    "                filtered_prediction['scores'].append(max(label_scores))\n",
    "                filtered_prediction['boxes'].append(box)\n",
    "    return filtered_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-14 01:57:33,360][INFO]   Inference on image :1\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i,image in enumerate(dataset.imgs):\n",
    "    if i %100 == 0:\n",
    "        logger.info(f'Inference on image :{i+1}')\n",
    "    img, label = dataset[i]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img.to(device)])\n",
    "    prediction = prediction[0]\n",
    "    predictions.append((i,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, {'boxes': tensor([[ 432.8447, 1420.0175,  577.8386, 1559.0612],\n",
       "           [ 547.2342, 1369.4414,  790.2762, 1527.8795],\n",
       "           [ 641.0007, 1299.5469,  818.5339, 1440.0417],\n",
       "           [ 764.3564, 1229.0747,  875.6802, 1354.4175],\n",
       "           [1004.7511,  694.2111, 1180.4651,  842.4067],\n",
       "           [ 705.4565,  356.0432,  824.7529,  468.3567],\n",
       "           [ 709.7260,  641.4727,  857.2224,  777.9129],\n",
       "           [ 897.0338,  882.3805, 1056.0146, 1032.3627],\n",
       "           [ 779.6442, 1179.9446,  924.6586, 1305.1759],\n",
       "           [ 527.8812, 1375.4147,  670.0339, 1477.6821],\n",
       "           [ 151.5519,  647.8757,  258.3089,  750.8358],\n",
       "           [ 296.6311,  812.3859,  430.1847,  939.7965],\n",
       "           [ 426.6754,  743.9402,  553.1544,  855.6308],\n",
       "           [ 272.4916,  492.8159,  406.4879,  603.2687],\n",
       "           [ 554.6608,  682.0419,  695.4303,  802.7009],\n",
       "           [ 481.7538,  358.1426,  607.2825,  459.2941],\n",
       "           [ 481.3268,  355.1777,  606.9153,  461.4102],\n",
       "           [ 545.4318,  675.8818,  690.5430,  806.6729],\n",
       "           [ 477.9369,  355.7949,  610.9528,  466.5614]], device='cuda:0'),\n",
       "   'labels': tensor([22, 21, 20, 19, 12, 13,  8,  7, 18, 17, 16, 11, 10, 15,  9, 14, 15, 10,\n",
       "           36], device='cuda:0'),\n",
       "   'scores': tensor([0.9991, 0.9982, 0.9968, 0.9965, 0.9956, 0.9949, 0.9941, 0.9937, 0.9928,\n",
       "           0.9905, 0.9885, 0.9850, 0.9824, 0.9116, 0.7696, 0.6658, 0.5035, 0.3618,\n",
       "           0.0698], device='cuda:0')}),\n",
       " (1, {'boxes': tensor([[ 687.7994, 1458.6133,  857.9899, 1631.5864],\n",
       "           [ 177.6104,  682.8054,  356.1864,  838.0932],\n",
       "           [ 453.6111,  672.3514,  599.9640,  808.3721],\n",
       "           [ 473.4126, 1332.7754,  656.3215, 1483.4443],\n",
       "           [ 632.5859, 1401.0812,  786.8356, 1507.4202],\n",
       "           [ 464.8062,  389.8329,  602.1806,  506.2745],\n",
       "           [ 500.2205, 1390.3772,  756.4136, 1565.8743],\n",
       "           [1057.4536,  713.0685, 1168.5962,  821.3564],\n",
       "           [ 749.7459,  774.0761,  887.8804,  894.7795],\n",
       "           [ 402.1634, 1262.3816,  528.1226, 1383.6859],\n",
       "           [ 300.1307,  892.0417,  455.8633, 1033.3827],\n",
       "           [ 878.6692,  504.5145, 1013.4010,  636.2307],\n",
       "           [ 358.3933, 1211.0189,  507.8729, 1320.6667],\n",
       "           [ 871.5178,  859.7137, 1005.1031,  994.8973],\n",
       "           [ 691.2793,  393.6394,  822.8578,  506.2806],\n",
       "           [ 612.0936,  707.2781,  755.3369,  847.7236],\n",
       "           [ 608.2371,  712.4998,  756.3899,  849.5803],\n",
       "           [ 691.8908,  393.0740,  818.3307,  503.6719],\n",
       "           [ 582.1149, 1362.8394,  771.5481, 1496.3082],\n",
       "           [ 688.5297,  390.8464,  822.1995,  508.5644]], device='cuda:0'),\n",
       "   'labels': tensor([44, 34, 30, 42, 39, 35, 43, 38, 32, 41, 29, 37, 40, 33, 36, 32, 31, 37,\n",
       "           39, 14], device='cuda:0'),\n",
       "   'scores': tensor([0.9987, 0.9984, 0.9968, 0.9960, 0.9951, 0.9949, 0.9948, 0.9941, 0.9938,\n",
       "           0.9930, 0.9915, 0.9914, 0.9879, 0.9858, 0.7498, 0.6352, 0.4246, 0.2183,\n",
       "           0.0977, 0.0938], device='cuda:0')}),\n",
       " (2, {'boxes': tensor([[ 620.1608, 1464.1991,  864.9274, 1649.3741],\n",
       "           [ 496.1154, 1519.0319,  640.0385, 1662.5779],\n",
       "           [ 696.3318, 1408.0471,  862.0565, 1551.0742],\n",
       "           [1002.1757, 1048.0748, 1136.9757, 1180.1772],\n",
       "           [ 835.7918, 1305.3042,  969.2595, 1420.8188],\n",
       "           [ 575.4672, 1492.3119,  728.8865, 1579.8928],\n",
       "           [1108.6699,  855.7625, 1271.3241, 1004.7316],\n",
       "           [ 474.4065,  557.1708,  583.0161,  672.7708],\n",
       "           [ 286.3475,  709.7748,  395.8208,  822.3517],\n",
       "           [ 808.1693, 1330.2406,  921.7313, 1454.6901],\n",
       "           [ 529.9348,  846.6516,  648.3054,  974.9485],\n",
       "           [ 657.9277,  780.4297,  787.4337,  910.7806],\n",
       "           [ 810.0064,  782.3268,  939.2181,  912.1040],\n",
       "           [ 403.6736,  907.4111,  527.9847, 1039.4344],\n",
       "           [ 838.9513,  487.2492,  945.2918,  606.4208],\n",
       "           [ 667.8495,  452.6429,  782.1976,  579.6453],\n",
       "           [ 672.1540,  447.8749,  785.5184,  575.9296]], device='cuda:0'),\n",
       "   'labels': tensor([21, 22, 20,  7, 18, 17, 12, 15, 16, 19, 10,  9,  8, 11, 13, 14, 36],\n",
       "          device='cuda:0'),\n",
       "   'scores': tensor([0.9994, 0.9987, 0.9985, 0.9969, 0.9964, 0.9954, 0.9953, 0.9951, 0.9945,\n",
       "           0.9938, 0.9935, 0.9929, 0.9900, 0.9894, 0.9793, 0.6941, 0.5242],\n",
       "          device='cuda:0')}),\n",
       " (3, {'boxes': tensor([[ 538.1859, 1566.0453,  771.1039, 1752.0400],\n",
       "           [ 751.0601, 1628.9613,  900.0344, 1769.1547],\n",
       "           [ 137.8950,  937.9015,  296.1402, 1083.5779],\n",
       "           [ 426.7461, 1392.6832,  560.9471, 1509.3600],\n",
       "           [ 531.7198, 1512.3391,  686.1928, 1654.5494],\n",
       "           [ 503.1512,  589.4103,  612.6225,  705.5093],\n",
       "           [ 281.3438, 1117.3044,  420.4365, 1253.2466],\n",
       "           [ 850.3263,  679.9008,  959.5486,  795.9870],\n",
       "           [ 777.5355,  976.9406,  898.2596, 1097.8947],\n",
       "           [ 498.2620,  885.6158,  624.2377, 1009.5184],\n",
       "           [ 663.8162, 1587.6514,  809.1545, 1683.9260],\n",
       "           [ 999.3801,  820.1528, 1105.6777,  923.5870],\n",
       "           [ 467.7433, 1429.9576,  584.7952, 1553.2877],\n",
       "           [ 896.9271, 1039.3120, 1025.9019, 1167.5472],\n",
       "           [ 646.3360,  898.8834,  770.4200, 1030.9725],\n",
       "           [ 653.7349,  570.2382,  764.3909,  689.4131],\n",
       "           [ 648.9440,  568.4047,  761.0229,  691.1425]], device='cuda:0'),\n",
       "   'labels': tensor([43, 44, 34, 40, 42, 35, 29, 37, 32, 30, 39, 38, 41, 33, 31, 36, 14],\n",
       "          device='cuda:0'),\n",
       "   'scores': tensor([0.9991, 0.9983, 0.9976, 0.9965, 0.9962, 0.9960, 0.9950, 0.9948, 0.9939,\n",
       "           0.9938, 0.9909, 0.9881, 0.9867, 0.9856, 0.9779, 0.6403, 0.3817],\n",
       "          device='cuda:0')})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Randomly checking 9 images at a time\n",
    "# import random\n",
    "# idx = list(range(len(predictions)))\n",
    "# random.shuffle(idx)\n",
    "# fig,axes = plt.subplots(figsize = (120,210), dpi = 20, nrows = 3, ncols = 3)\n",
    "# axes = axes.flatten()\n",
    "# for i in range(9):\n",
    "#     j, prediction = predictions[idx[i]]\n",
    "#     print(f'Local ID: {idx[i]}, Global ID: {j}')\n",
    "#     img, label = dataset[j]\n",
    "#     visualize(img, prediction, True, ax = axes[i],erosion = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 14:23:42,827][INFO]   Apply filter at threshold = 0\n",
      "[2020-05-09 14:23:42,830][WARNING]   Number of underlabel images: 0\n",
      "[2020-05-09 14:23:42,831][WARNING]   Number of underlabel joints: 0\n",
      "[2020-05-09 14:23:42,832][WARNING]   Underlabels: {}\n"
     ]
    }
   ],
   "source": [
    "threshold = 0\n",
    "filtered_predictions = []\n",
    "underlabel = {}\n",
    "limbs = ['LH', 'RH', 'LF', 'RF']\n",
    "logger.info(f'Apply filter at threshold = {threshold}')\n",
    "for i,prediction in enumerate(predictions):\n",
    "    limb = [limb for limb in limbs if limb in dataset.imgs[i]][0]\n",
    "    LABELS = [NAME_TO_ID_MAP[x] for x in NAME_TO_ID_MAP.keys() if limb in x]\n",
    "    filtered_prediction = filter_prediction(prediction[1], 0, LABELS)\n",
    "    filtered_predictions.append((prediction[0], filtered_prediction))\n",
    "    if len(filtered_prediction['labels']) < len(LABELS):\n",
    "        underlabel[i] = set(LABELS) - set(filtered_prediction['labels'])\n",
    "logger.warning(f'Number of underlabel images: {len(underlabel)}')\n",
    "logger.warning(f'Number of underlabel joints: {len([y for x in underlabel.values() for y in x])}')\n",
    "logger.warning(f'Underlabels: {underlabel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#underlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Randomly checking 9 images at a time\n",
    "# import random\n",
    "# #idx = list(range(len(filtered_predictions)))\n",
    "# idx = list(underlabel.keys())\n",
    "# random.shuffle(idx)\n",
    "# fig,axes = plt.subplots(figsize = (120,210), dpi = 20, nrows = 3, ncols = 3)\n",
    "# axes = axes.flatten()\n",
    "# for i in range(9):\n",
    "#     j, prediction = filtered_predictions[idx[i]]\n",
    "#     print(f'Local ID: {idx[i]}, Global ID: {j}')\n",
    "#     img, label = dataset[j]\n",
    "#     visualize(img, prediction, True, ax = axes[i],erosion = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out joint images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 14:23:44,444][INFO]   Wrote 16 joint images for UAB001-LH\n",
      "[2020-05-09 14:23:44,512][INFO]   Wrote joint images detected from 1 images\n",
      "[2020-05-09 14:23:44,513][INFO]   Wrote 16 joint images for UAB001-RH\n",
      "[2020-05-09 14:23:44,599][INFO]   Wrote 16 joint images for UAB002-LH\n",
      "[2020-05-09 14:23:44,686][INFO]   Wrote 16 joint images for UAB002-RH\n",
      "[2020-05-09 14:23:44,687][INFO]    Wrote 64 joint images for 4\n",
      "[2020-05-09 14:23:44,687][INFO]   Complete!\n"
     ]
    }
   ],
   "source": [
    "joint_count = 0\n",
    "for i in range(len(dataset)):\n",
    "    image_id = dataset.imgs[i].strip('.jpg')\n",
    "    img,_ = dataset[i]\n",
    "    img = img.mul(255).permute(1,2,0).byte().numpy()\n",
    "    for j,box in enumerate(filtered_predictions[i][1]['boxes']):\n",
    "        xmin, ymin, xmax, ymax = box[0]\n",
    "        label = int(filtered_predictions[i][1]['labels'][j])\n",
    "        joint_img = Image.fromarray(img[int(np.ceil(ymin)):int(np.floor(ymax)),int(np.ceil(xmin)):int(np.floor(xmax)), :], 'RGB')\n",
    "        joint_img.save(os.path.join(JOINTOUTPUT, f'{image_id}-{label}.jpg'))\n",
    "        joint_count += 1\n",
    "    if i%100 == 1:\n",
    "        logger.info(f'Wrote joint images detected from {i} images')\n",
    "    logger.info(f'Wrote {len(filtered_predictions[i][1][\"labels\"])} joint images for {image_id}')\n",
    "logger.info(f' Wrote {joint_count} joint images for {len(dataset)}')\n",
    "logger.info('Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the feet joints over but be careful about the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 14:24:13,122][INFO]   Copied 24 feet joints from narrowing to erosion\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from data import ID_TO_NAME_MAP_NARROWING\n",
    "count = 0\n",
    "for img in os.listdir(handle +'/test/narrowing_all'):\n",
    "    if ('LF' in img) or ('RF' in img):\n",
    "        name = img.strip('.jpg').split('-')\n",
    "        name[2] = str(NAME_TO_ID_MAP[ID_TO_NAME_MAP_NARROWING[int(name[2])]])\n",
    "        count += 1\n",
    "        shutil.copy(os.path.join(handle +'/test/narrowing_all', img), os.path.join(handle +'/test/erosion_all', '-'.join(name)+'.jpg'))\n",
    "logger.info(f'Copied {count} feet joints from narrowing to erosion') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of torchvision_finetuning_instance_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0453a3e19be44d1d9bb80bfaeaf791c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4625f727c02b4bc390bc63e41a71f160": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49a6b019ee9640e4869de8a4a053abf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50a2d0864b2e4a3fba07236a9dc06ff8",
      "placeholder": "​",
      "style": "IPY_MODEL_8ad6c44dcacb4ea79dd9e26b0ff5188a",
      "value": " 160M/160M [00:40&lt;00:00, 4.11MB/s]"
     }
    },
    "50a2d0864b2e4a3fba07236a9dc06ff8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ad6c44dcacb4ea79dd9e26b0ff5188a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95305316dcd34c71ac1cb75c997c4b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c63e1e5a3e59405f8a656259859d28c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0453a3e19be44d1d9bb80bfaeaf791c1",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95305316dcd34c71ac1cb75c997c4b58",
      "value": 167502836
     }
    },
    "cc3721079bb84b0182a2c194721b7405": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c63e1e5a3e59405f8a656259859d28c8",
       "IPY_MODEL_49a6b019ee9640e4869de8a4a053abf1"
      ],
      "layout": "IPY_MODEL_4625f727c02b4bc390bc63e41a71f160"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
